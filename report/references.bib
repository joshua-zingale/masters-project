@article{nussbaum2024nomic,
  title={Nomic embed: Training a reproducible long context text embedder},
  author={Nussbaum, Zach and Morris, John X and Duderstadt, Brandon and Mulyar, Andriy},
  journal={arXiv preprint arXiv:2402.01613},
  year={2024}
}

@article{baillifard2025effective,
  title={Effective learning with a personal AI tutor: A case study},
  author={Baillifard, Ambroise and Gabella, Maxime and Lavenex, Pamela Banta and Martarelli, Corinna S},
  journal={Education and Information Technologies},
  volume={30},
  number={1},
  pages={297--312},
  year={2025},
  publisher={Springer}
}

@article{qinjin_jia_llm-generated_2024,
	title = {{LLM}-generated {Feedback} in {Real} {Classes} and {Beyond}: {Perspectives} from {Students} and {Instructors}},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {{LLM}-generated {Feedback} in {Real} {Classes} and {Beyond}},
	url = {https://zenodo.org/doi/10.5281/zenodo.12729974},
	doi = {10.5281/ZENODO.12729974},
	abstract = {Feedback plays a crucial role in education, offering students explicit guidance on how to enhance their academic performance. In pursuit of providing feedback promptly and efficiently, researchers are actively exploring the use of large language models (LLMs) to automatically generate feedback on student work. However, the deployment of such automated feedback systems in actual classrooms is nascent, and they have yet to survey student and instructor perspectives, thus leaving their limitations in real educational settings unclear. In this paper, we deploy a system that generates feedback for student project reports in a graduate-level computer science course and collect perspectives from authentic users. We solicited student opinions on the generated feedback through questionnaires and engaged the course instructor to delve into their perceptions regarding the alignment of the feedback with their pedagogical objectives. Our work sheds light on the potential impact and limitations of system-generated feedback in real-world educational settings and contributes insights for future research on automated feedback systems.},
	language = {en},
	urldate = {2024-10-30},
	author = {Qinjin Jia and Jialin Cui and Haoze Du and Parvez Rashid and Ruijie Xi and Ruochi Li and Edward Gehringer},
	collaborator = {Benjamin, Paa√üen and Carrie, Demmans Epp},
	month = jul,
	year = {2024},
	note = {Publisher: International Educational Data Mining Society},
	keywords = {read},
	file = {Qinjin Jia et al. - 2024 - LLM-generated Feedback in Real Classes and Beyond.pdf:/Users/agentwombat/Zotero/storage/A6I8CQ6J/Qinjin Jia et al. - 2024 - LLM-generated Feedback in Real Classes and Beyond.pdf:application/pdf},
}

@inproceedings{taylor_dcc_2024,
	address = {New York, NY, USA},
	series = {{SIGCSE} 2024},
	title = {dcc --help: {Transforming} the {Role} of the {Compiler} by {Generating} {Context}-{Aware} {Error} {Explanations} with {Large} {Language} {Models}},
	isbn = {9798400704239},
	shorttitle = {dcc --help},
	url = {https://dl.acm.org/doi/10.1145/3626252.3630822},
	doi = {10.1145/3626252.3630822},
	abstract = {In the challenging field of introductory programming, high enrolments and failure rates drive us to explore tools and systems to enhance student outcomes, especially automated tools that scale to large cohorts. This paper presents and evaluates the dcc --help tool, an integration of a Large Language Model (LLM) into the Debugging C Compiler (DCC) to generate unique, novice-focused explanations tailored to each error. dcc --help prompts an LLM with contextual information of compile- and run-time error occurrences, including the source code, error location and standard compiler error message. The LLM is instructed to generate novice-focused, actionable error explanations and guidance, designed to help students understand and resolve problems without providing solutions. dcc --help was deployed to our CS1 and CS2 courses, with 2,565 students using the tool over 64,000 times in ten weeks. We analysed a subset of these error/explanation pairs to evaluate their properties, including conceptual correctness, relevancy, and overall quality. We found that the LLM-generated explanations were conceptually accurate in 90\% of compile-time and 75\% of run-time cases, but often disregarded the instruction not to provide solutions in code. Our findings, observations and reflections following deployment indicate that dcc --help provides novel opportunities for scaffolding students' introduction to programming.},
	urldate = {2024-10-14},
	booktitle = {Proceedings of the 55th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Taylor, Andrew and Vassar, Alexandra and Renzella, Jake and Pearce, Hammond},
	month = mar,
	year = {2024},
	keywords = {read},
	pages = {1314--1320},
	file = {Full Text PDF:/Users/agentwombat/Zotero/storage/IJSAJREM/Taylor et al. - 2024 - dcc --help Transforming the Role of the Compiler .pdf:application/pdf},
}


@inproceedings{neyem_exploring_2024,
	address = {New York, NY, USA},
	series = {{SIGCSE} 2024},
	title = {Exploring the {Impact} of {Generative} {AI} for {StandUp} {Report} {Recommendations} in {Software} {Capstone} {Project} {Development}},
	isbn = {9798400704239},
	url = {https://dl.acm.org/doi/10.1145/3626252.3630854},
	doi = {10.1145/3626252.3630854},
	abstract = {StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts.},
	urldate = {2024-10-14},
	booktitle = {Proceedings of the 55th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Neyem, Andres and Sandoval Alcocer, Juan Pablo and Mendoza, Marcelo and Centellas-Claros, Leonardo and Gonzalez, Luis A. and Paredes-Robles, Carlos},
	month = mar,
	year = {2024},
	keywords = {read},
	pages = {951--957},
	file = {Full Text PDF:/Users/agentwombat/Zotero/storage/MIBRWLEP/Neyem et al. - 2024 - Exploring the Impact of Generative AI for StandUp .pdf:application/pdf},
}

@inproceedings{kazemitabaar_codeaid_2024,
	address = {Honolulu HI USA},
	title = {{CodeAid}: {Evaluating} a {Classroom} {Deployment} of an {LLM}-based {Programming} {Assistant} that {Balances} {Student} and {Educator} {Needs}},
	isbn = {9798400703300},
	shorttitle = {{CodeAid}},
	url = {https://dl.acm.org/doi/10.1145/3613904.3642773},
	doi = {10.1145/3613904.3642773},
	language = {en},
	urldate = {2024-10-30},
	booktitle = {Proceedings of the {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Kazemitabaar, Majeed and Ye, Runlong and Wang, Xiaoning and Henley, Austin Zachary and Denny, Paul and Craig, Michelle and Grossman, Tovi},
	month = may,
	year = {2024},
	keywords = {read},
	pages = {1--20},
	file = {Full Text PDF:/Users/agentwombat/Zotero/storage/77KJ3XHZ/Kazemitabaar et al. - 2024 - CodeAid Evaluating a Classroom Deployment of an L.pdf:application/pdf},
}

@article{ji2023survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM computing surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{kirchenbauer2024hallucination,
  title={Hallucination reduction in large language models with retrieval-augmented generation using wikipedia knowledge},
  author={Kirchenbauer, Jason and Barns, Caleb},
  journal={ArXiv Preprint. https://doi. org/10.31219/osf. io/pv7r5},
  year={2024}
}

@inproceedings{soudani2024fine,
  title={Fine tuning vs. retrieval augmented generation for less popular knowledge},
  author={Soudani, Heydar and Kanoulas, Evangelos and Hasibi, Faegheh},
  booktitle={Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
  pages={12--22},
  year={2024}
}

@inproceedings{liu2024teaching,
  title={Teaching CS50 with AI: leveraging generative artificial intelligence in computer science education},
  author={Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J},
  booktitle={Proceedings of the 55th ACM technical symposium on computer science education V. 1},
  pages={750--756},
  year={2024}
}

@article{naveed2025comprehensive,
author = {Naveed, Humza and Khan, Asad Ullah and Qiu, Shi and Saqib, Muhammad and Anwar, Saeed and Usman, Muhammad and Akhtar, Naveed and Barnes, Nick and Mian, Ajmal},
title = {A Comprehensive Overview of Large Language Models},
year = {2025},
issue_date = {October 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {5},
issn = {2157-6904},
url = {https://doi.org/10.1145/3744746},
doi = {10.1145/3744746},
abstract = {Large Language Models (LLMs) have recently demonstrated remarkable capabilities in natural language processing tasks and beyond. This success of LLMs has led to a large influx of research contributions in this direction. These works encompass diverse topics such as architectural innovations, better training strategies, context length improvements, fine-tuning, multimodal LLMs, robotics, datasets, benchmarking, efficiency, and more. With the rapid development of techniques and regular breakthroughs in LLM research, it has become considerably challenging to perceive the bigger picture of the advances in this direction. Considering the rapidly emerging plethora of literature on LLMs, it is imperative that the research community is able to benefit from a concise yet comprehensive overview of the recent developments in this field. This article provides an overview of the literature on a broad range of LLM-related concepts. Our self-contained comprehensive overview of LLMs discusses relevant background concepts along with covering the advanced topics at the frontier of research in LLMs. This review article is intended to provide not only a systematic survey but also a quick, comprehensive reference for the researchers and practitioners to draw insights from extensive, informative summaries of the existing works to advance the LLM research.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = aug,
articleno = {106},
numpages = {72},
keywords = {Large Language Models, LLMs, chatGPT, Augmented LLMs, Multimodal LLMs, LLM training, LLM Benchmarking}
}